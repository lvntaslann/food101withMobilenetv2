{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fd6277a-f901-4371-ba0e-78ce098b1936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import stat\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.image as img\n",
    "import random\n",
    "import cv2\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "from ipywidgets import interact, interactive, fixed\n",
    "import ipywidgets as widgets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.io import imread\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.models import load_model\n",
    "from shutil import copy\n",
    "from shutil import copytree, rmtree\n",
    "import tensorflow.keras.backend \n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import models\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67dd5900-7604-433e-9f84-5126bd5ac4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to load train-test files.\n",
    "def load_train_test_data(path_to_train_imgs, path_to_test_imgs):\n",
    "    X_train, y_train = load_images(path_to_train_imgs)\n",
    "    X_test, y_test = load_images(path_to_test_imgs)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "014d538a-7b96-48fd-bee1-4158f9891424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 75750 images belonging to 101 classes.\n",
      "Found 25250 images belonging to 101 classes.\n",
      "Epoch 1/20\n",
      "2367/2367 [==============================] - 941s 397ms/step - loss: 2.3664 - accuracy: 0.4391 - val_loss: 2.4431 - val_accuracy: 0.4592\n",
      "Epoch 2/20\n",
      "2367/2367 [==============================] - 859s 363ms/step - loss: 1.5563 - accuracy: 0.6092 - val_loss: 2.4908 - val_accuracy: 0.4577\n",
      "Epoch 3/20\n",
      "2367/2367 [==============================] - 856s 361ms/step - loss: 1.3187 - accuracy: 0.6634 - val_loss: 1.9697 - val_accuracy: 0.5575\n",
      "Epoch 4/20\n",
      "2367/2367 [==============================] - 852s 360ms/step - loss: 1.1544 - accuracy: 0.7010 - val_loss: 1.5789 - val_accuracy: 0.6202\n",
      "Epoch 5/20\n",
      "2367/2367 [==============================] - 855s 361ms/step - loss: 1.0477 - accuracy: 0.7248 - val_loss: 1.9896 - val_accuracy: 0.5360\n",
      "Epoch 6/20\n",
      "2367/2367 [==============================] - 855s 361ms/step - loss: 0.9541 - accuracy: 0.7484 - val_loss: 1.7413 - val_accuracy: 0.6018\n",
      "Epoch 7/20\n",
      "2367/2367 [==============================] - 852s 360ms/step - loss: 0.8849 - accuracy: 0.7624 - val_loss: 1.6480 - val_accuracy: 0.6080\n",
      "Epoch 8/20\n",
      "2367/2367 [==============================] - 865s 365ms/step - loss: 0.8305 - accuracy: 0.7779 - val_loss: 1.4396 - val_accuracy: 0.6524\n",
      "Epoch 9/20\n",
      "2367/2367 [==============================] - 884s 373ms/step - loss: 0.7679 - accuracy: 0.7931 - val_loss: 1.5408 - val_accuracy: 0.6488\n",
      "Epoch 10/20\n",
      "2367/2367 [==============================] - 859s 363ms/step - loss: 0.7183 - accuracy: 0.8046 - val_loss: 1.5155 - val_accuracy: 0.6577\n",
      "Epoch 11/20\n",
      "2367/2367 [==============================] - 863s 365ms/step - loss: 0.6753 - accuracy: 0.8151 - val_loss: 1.4065 - val_accuracy: 0.6801\n",
      "Epoch 12/20\n",
      "2367/2367 [==============================] - 859s 363ms/step - loss: 0.6320 - accuracy: 0.8261 - val_loss: 1.5160 - val_accuracy: 0.6401\n",
      "Epoch 13/20\n",
      "2367/2367 [==============================] - 859s 363ms/step - loss: 0.5945 - accuracy: 0.8338 - val_loss: 1.4685 - val_accuracy: 0.6624\n",
      "Epoch 14/20\n",
      "2367/2367 [==============================] - 860s 363ms/step - loss: 0.5641 - accuracy: 0.8413 - val_loss: 1.3394 - val_accuracy: 0.6965\n",
      "Epoch 15/20\n",
      "2367/2367 [==============================] - 857s 362ms/step - loss: 0.5353 - accuracy: 0.8488 - val_loss: 1.3956 - val_accuracy: 0.6700\n",
      "Epoch 16/20\n",
      "2367/2367 [==============================] - 855s 361ms/step - loss: 0.5106 - accuracy: 0.8547 - val_loss: 1.7846 - val_accuracy: 0.6319\n",
      "Epoch 17/20\n",
      "2367/2367 [==============================] - 860s 363ms/step - loss: 0.4732 - accuracy: 0.8636 - val_loss: 1.4036 - val_accuracy: 0.6969\n",
      "Epoch 18/20\n",
      "2367/2367 [==============================] - 875s 370ms/step - loss: 0.4515 - accuracy: 0.8707 - val_loss: 1.2966 - val_accuracy: 0.6971\n",
      "Epoch 19/20\n",
      "2367/2367 [==============================] - 852s 360ms/step - loss: 0.4320 - accuracy: 0.8752 - val_loss: 1.3739 - val_accuracy: 0.6935\n",
      "Epoch 20/20\n",
      "2367/2367 [==============================] - 852s 360ms/step - loss: 0.4089 - accuracy: 0.8818 - val_loss: 1.4346 - val_accuracy: 0.6841\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adamax\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "import numpy as np\n",
    "\n",
    "# Clearing the session\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Defining parameters\n",
    "n_classes = 101\n",
    "img_width, img_height = 224, 224\n",
    "train_data_dir = r\"C:\\Users\\kurt_\\Desktop\\food-101\\train\"\n",
    "validation_data_dir = r\"C:\\Users\\kurt_\\Desktop\\food-101\\test\"\n",
    "nb_train_samples = 75750\n",
    "nb_validation_samples = 25250\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "\n",
    "# Data generators\n",
    "def add_gaussian_noise(image):\n",
    "    noise = np.random.normal(loc=0, scale=0.1, size=image.shape)\n",
    "    return image + noise\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],  # Rastgele parlaklık\n",
    "    preprocessing_function=add_gaussian_noise  # Gauss gürültüsü\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "# MobileNetV2 model\n",
    "mbv2 = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "x = mbv2.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "predictions = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=mbv2.input, outputs=predictions)\n",
    "model.compile(optimizer=Adamax(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "checkpointer = ModelCheckpoint(filepath='best_model_101class_mobilenetv2den3.hdf5', save_best_only=True)\n",
    "csv_logger = CSVLogger('history_101class_mobilenetv2den3.log')\n",
    "\n",
    "# Training the model\n",
    "history_101class_mobilenetv2den3 = model.fit(train_generator,\n",
    "                    steps_per_epoch=nb_train_samples // batch_size,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=nb_validation_samples // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpointer, csv_logger])\n",
    "\n",
    "# Saving the trained model\n",
    "model.save('model_trained_101class_mobilenetv2den3.hdf5')\n",
    "print('Training completed.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09c5b717-fbca-4ec6-b068-519f2df9cf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"C:\\Users\\kurt_\\best_model_101class_mobilenetv2den3.hdf5\"\n",
    "test_data_path = r\"C:\\Users\\kurt_\\Desktop\\food-101\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13a1e21d-99fc-4b20-8248-15f685efb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performans metriklerini hesaplamak için fonksiyon tanımla\n",
    "def calculate_metrics(model, test_gen):\n",
    "    # Modelden tahminler yap\n",
    "    predictions = model.predict(test_gen)\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    # Gerçek sınıfları al\n",
    "    true_classes = test_gen.classes\n",
    "    \n",
    "    # Sınıf etiketlerini al\n",
    "    class_labels = list(test_gen.class_indices.keys())\n",
    "\n",
    "    # Doğruluk, hassasiyet, geri çağırma ve F1 puanını hesapla\n",
    "    accuracy = accuracy_score(true_classes, predicted_classes)\n",
    "    precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "    recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "    f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f4ce5845-8a15-4471-906e-5669ca30b196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25250 images belonging to 101 classes.\n",
      "790/790 [==============================] - 67s 84ms/step\n",
      "Accuracy: 0.6971089108910891\n",
      "Precision: 0.7263331105641404\n",
      "Recall: 0.6971089108910891\n",
      "F1 Score: 0.6995881159377603\n"
     ]
    }
   ],
   "source": [
    "# Boyutları tanımla\n",
    "height, width = 224, 224\n",
    "\n",
    "# Batch boyutunu tanımla\n",
    "batch_size = 32\n",
    "\n",
    "# Test veri üreteci oluştur\n",
    "test_data_gen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_gen = test_data_gen.flow_from_directory(test_data_path, target_size=(height, width), batch_size=batch_size, class_mode='categorical', shuffle=False)\n",
    "\n",
    "# Modeli yükle\n",
    "model = load_model(model_path, compile=False)\n",
    "\n",
    "# Performans metriklerini hesapla\n",
    "accuracy, precision, recall, f1_score = calculate_metrics(model, test_gen)\n",
    "\n",
    "# Hesaplanan metrikleri yazdır\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084b4f63-c4e9-4d7d-bc7e-ba17ecfab571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
